[
    [
        "function_str",
        "def extract_slices(preprocessed_T1, slice_direction=0, slice_mode='original'):\n    \"\"\"\n    This is to extract the slices from three directions\n    :param preprocessed_T1:\n    :param slice_direction: which axis direction that the slices were extracted\n    :return:\n    \"\"\"\n    import torch, os\n\n    image_tensor = torch.load(preprocessed_T1)\n    ## reshape the tensor, delete the first dimension for slice-level\n    image_tensor = image_tensor.view(image_tensor.shape[1], image_tensor.shape[2], image_tensor.shape[3])\n\n    ## sagital\n    slice_list_sag = range(20, image_tensor.shape[0] - 20) # delete the first 20 slice and last 20 slices\n\n    if slice_direction == 0:\n        for index_slice in slice_list_sag:\n            # for i in slice_list:\n            ## sagital\n            slice_select_sag = image_tensor[index_slice, :, :]\n\n            ## convert the slices to images based on if transfer learning or not\n            # train from scratch\n            extracted_slice_original_sag = slice_select_sag.unsqueeze(0) ## shape should be 1 * W * L\n\n            # train for transfer learning, creating the fake RGB image.\n            slice_select_sag = (slice_select_sag - slice_select_sag.min()) / (slice_select_sag.max() - slice_select_sag.min())\n            extracted_slice_rgb_sag = torch.stack((slice_select_sag, slice_select_sag, slice_select_sag)) ## shape should be 3 * W * L\n\n            # save into .pt format\n            if slice_mode == 'original':\n                output_file_original = os.path.join(os.path.dirname(preprocessed_T1), preprocessed_T1.split('.pt')[0] + '_axis-sag_originalslice-' + str(index_slice) + '.pt')\n                torch.save(extracted_slice_original_sag, output_file_original)\n            elif slice_mode == 'rgb':\n                output_file_rgb = os.path.join(os.path.dirname(preprocessed_T1), preprocessed_T1.split('.pt')[0] + '_axis-sag_rgbslice-' + str(index_slice) + '.pt')\n                torch.save(extracted_slice_rgb_sag, output_file_rgb)\n\n    elif slice_direction == 1:\n        ## cornal\n        slice_list_cor = range(15, image_tensor.shape[1] - 15) # delete the first 20 slice and last 15 slices\n        for index_slice in slice_list_cor:\n            # for i in slice_list:\n            ## sagital\n            slice_select_cor = image_tensor[:, index_slice, :]\n\n            ## convert the slices to images based on if transfer learning or not\n            # train from scratch\n            extracted_slice_original_cor = slice_select_cor.unsqueeze(0) ## shape should be 1 * W * L\n\n            # train for transfer learning, creating the fake RGB image.\n            slice_select_cor = (slice_select_cor - slice_select_cor.min()) / (slice_select_cor.max() - slice_select_cor.min())\n            extracted_slice_rgb_cor = torch.stack((slice_select_cor, slice_select_cor, slice_select_cor)) ## shape should be 3 * W * L\n\n            # save into .pt format\n            if slice_mode == 'original':\n                output_file_original = os.path.join(os.path.dirname(preprocessed_T1), preprocessed_T1.split('.pt')[0] + '_axis-cor_originalslice-' + str(index_slice) + '.pt')\n                torch.save(extracted_slice_original_cor, output_file_original)\n            elif slice_mode == 'rgb':\n                output_file_rgb = os.path.join(os.path.dirname(preprocessed_T1), preprocessed_T1.split('.pt')[0] + '_axis-cor_rgblslice-' + str(index_slice) + '.pt')\n                torch.save(extracted_slice_rgb_cor, output_file_rgb)\n\n    else:\n\n        ## axial\n        slice_list_axi = range(15, image_tensor.shape[2] - 15) # delete the first 20 slice and last 15 slices\n        for index_slice in slice_list_axi:\n            # for i in slice_list:\n            ## sagital\n            slice_select_axi = image_tensor[:, :, index_slice]\n\n            ## convert the slices to images based on if transfer learning or not\n            # train from scratch\n            extracted_slice_original_axi = slice_select_axi.unsqueeze(0) ## shape should be 1 * W * L\n\n            # train for transfer learning, creating the fake RGB image.\n            slice_select_axi = (slice_select_axi - slice_select_axi.min()) / (slice_select_axi.max() - slice_select_axi.min())\n            extracted_slice_rgb_axi = torch.stack((slice_select_axi, slice_select_axi, slice_select_axi)) ## shape should be 3 * W * L\n\n            # save into .pt format\n            if slice_mode == 'original':\n                output_file_original = os.path.join(os.path.dirname(preprocessed_T1), preprocessed_T1.split('.pt')[0] + '_axis-axi_originalslice-' + str(index_slice) + '.pt')\n                torch.save(extracted_slice_original_axi, output_file_original)\n            elif slice_mode == 'rgb':\n                output_file_rgb = os.path.join(os.path.dirname(preprocessed_T1), preprocessed_T1.split('.pt')[0] + '_axis-axi_rgblslice-' + str(index_slice) + '.pt')\n                torch.save(extracted_slice_rgb_axi, output_file_rgb)\n\n    return preprocessed_T1\n"
    ],
    [
        "preprocessed_T1",
        [
            [
                "/network/lustre/dtlake01/aramis/projects/clinica/CLINICA_datasets/CAPS/Frontiers_DL/ADNI_CAPS_test/subjects/sub-ADNI002S0619/ses-M00/t1/preprocessing_dl/sub-ADNI002S0619_ses-M00_space-MNI_res-1x1x1.pt",
                "b86d4bf45b03d0a020f3dc9d5bcfb6ef"
            ]
        ]
    ],
    [
        "slice_direction",
        0
    ],
    [
        "slice_mode",
        "original"
    ],
    [
        "needed_outputs",
        [
            "preprocessed_T1"
        ]
    ]
]