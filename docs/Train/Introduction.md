# `train` - Train deep learning networks for neuroimaging classification

This pipeline enables the training of a convolutional neural network (CNN) classifier using different formats of inputs 
(whole 3D images, 3D patches or 2D slices), as defined in [[Wen et al., 2020](https://doi.org/10.1016/j.media.2020.101694)]. 
It mainly relies on the PyTorch deep learning library 
[[Paszke et al., 2019](https://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library)].

## Prerequisites
You need to execute the [`clinicadl tsvtool getlabels`](../TSVTools.md#getlabels-extract-labels-specific-to-alzheimers-disease) 
and [`clinicadl tsvtool {split|kfold}`](../TSVTools.md#split-single-split-observing-similar-age-and-sex-distributions) pipelines
prior to running this pipeline to have the correct TSV file organization.
Moreover, there should be a CAPS, obtained running the `t1-linear` pipeline of ClinicaDL.

## Running the pipeline
The pipeline can be run with the following command line:
```
clinicadl train <mode> <network_type> <caps_directory> \
                <preprocessing> <tsv_path> <output_directory> <architecture>
```
where mandatory arguments are:

- `mode` (str) is the type of input used. Must be chosen between `image`, `patch`, `roi` and `slice`.
- `network_type` (str) is the type of network used. 
The options depend on the type of input used, but at most it can be chosen between `autoencoder`, `cnn` and `multicnn`.
- `caps_directory` (str) is the input folder containing the neuroimaging data in a [CAPS](http://www.clinica.run/doc/CAPS/Introduction/) hierarchy.
- `preprocessing` (str) corresponds to the preprocessing pipeline whose outputs will be used for training. 
The current version only supports `t1-linear`, but `t1-extensive` will be implemented in next versions of `clinicadl`.
- `tsv_path` (str) is the input folder of a TSV file tree generated by `clinicadl tsvtool {split|kfold}`.
- `output_directory` (str) is the folder where the results are stored.
- `architecture` (str) is the name of the architecture used (e.g. `Conv5_FC3`). 
It must correspond to a class that inherits from `nn.Module` imported in `tools/deep_learning/models/__init__.py`.

Options shared among all pipelines are organized in groups:

- **Computational resources**
    - `--use_cpu` (bool) forces to use CPU. Default behaviour is to try to use a GPU and to raise an error if it is not found.
    - `--nproc` (int) is the number of workers used by the DataLoader. Default value: `2`.
    - `--batch_size` (int) is the size of the batch used in the DataLoader. Default value: `2`.
- **Data management**
    - `--diagnoses` (list of str) is the list of the labels that will be used for training. 
    These labels must be chosen from {AD,CN,MCI,sMCI,pMCI}. Default will use AD and CN labels.
    - `--baseline` (bool) is a flag to perform the load only _baseline.tsv files instead of .tsv files comprising all the sessions. Default: `False`.
    - `--unnormalize` (bool) is a flag to disable min-max normalization that is performed by default. Default: `False`.
- **Cross-validation arguments**
    - `--n_splits` (int) is a number of splits k to load in the case of a k-fold cross-validation. Default will load a single-split.
    - `--split` (list of int) is a subset of folds that will be used for training. By default all splits available are used. 
- **Optimization parameters**
    - `--epochs` (int) is the maximum number of epochs. Default: `20`.
    - `--learning_rate` (float) is the learning rate used to perform weights update. Default: `1e-4`.
    - `--weight_decay` (float) is the weight decay used by Adam optimizer. Default: `1e-4`.
    - `--dropout` (float) is the rate of dropout applied in dropout layers. Default will reproduce the dropout rates used in 
    [[Wen et al.](https://doi.org/10.1016/j.media.2020.101694)].
    - `--patience` (int) is the number of epochs for early stopping patience. Default: `10`.
    - `--tolerance` (float) is the value used for early stopping tolerance. Default: `0`.
    - `--evaluation_steps` (int) gives the number of iterations to perform an evaluation internal to an epoch. 
    Default will only perform one evaluation at the end of each epoch.
    - `--accumulation_steps` (int) gives the number of iterations during which gradients are accumulated before performing the weights update. 
    This allows to virtually increase the size of the batch. Default: `1`.

!!! note "Specific options"
    Other pipeline options are highly dependent on the input and the type of network used. 
    Please refer to the corresponding sections for more information.

!!! tip
    Typing `clinicadl train {image|patch|roi|slice} --help` will show you the networks that are available for training in this category.

## Outputs

At the first level of the file system, all pipeline outputs are identical.
Below is an example of the output file system for a network trained with data split between train and validation sets 
corresponding to a 5-fold cross-validation.

<pre>
results
├── commandline.json
├── environment.txt
├── <b>fold-0</b>
├── <b>fold-1</b>
├── <b>fold-2</b>
├── <b>fold-3</b>
└── <b>fold-4</b>
</pre>

where:

- `commandline.json` is a file containing all the arguments necessary to reproduce the experiment,
- `environment.txt` contains the version of `python` and `pytorch` used to run the experiment,
- `fold-<i>` is a folder containing the result of the run on the `i`-th split of the 5-fold cross-validation.

!!! note "Validation procedure"
    A run of `clinicadl train` is necessarily associated to a TSV file system defining a series of data splits (k-fold cross-validation or single split). 
    In the case of a single split the `results` folder will only contain a folder named `fold-0`.

The structure of the `fold-<i>` folders partly depends on the type of network trained. They may contain the following folders:

- `models` is the folder containing checkpoints saved at the end of each epoch, 
as well as the best model according to a specific metric on the validation set. 
The selection of a best model is only performed at the end of an epoch (a model cannot be selected based on internal evaluations in an epoch).
- `tensorboard_logs` contains logs that can be visualized with [TensorBoard](https://www.tensorflow.org/tensorboard).
- `cnn_classification` *specific to `(multi)cnn`* contains TSV files corresponding to the evaluation of the best models as saved in `models`.
- `autoencoder_reconstruction` *specific to `autoencoder`* contains reconstructions of the best model selected on the validation loss.

## Implementation details

Some architectures were implemented in `clinicadl` and corresponds to the ones used in [[Wen et al., 2020](https://doi.org/10.1016/j.media.2020.101694)]. 
These architectures present some specificites described here.

### Adaptive padding in pooling layers

Pooling layers reduce the size of their input feature maps. 
There are no learnable parameters in this layer, the kernel outputting the maximum value of the part of the feature map its kernels is covering.

Here is a 2D example of the standard layer of pytorch `nn.MaxPool2d`:

<img src="https://drive.google.com/uc?id=1qh9M9r9mfpZeSD1VjOGQAl8zWqBLmcKz" style="height: 200px;" alt="animation of classical max pooling">

The last column may not be used depending on the size of the kernel/input and stride value. 
To avoid this, pooling layers with adaptive padding `PadMaxPool3d` were implemented in `clinicadl` to exploit information from the whole feature map.

<img src="https://drive.google.com/uc?id=14R_LCTiV0N6ZXm-3wQCj_Gtc1LsXdQq_" style="height: 200px;" alt="animation of max pooling with adaptive pooling">

!!! note "Adapt the padding... or the input!"
    To avoid this problem, deep learners often choose to resize their input to have sizes 
    equal to 2<sup>n</sup> with maxpooling layers of size and stride of 2.

### Autoencoders construction from CNN architectures

In `clinicadl`, an autoencoder is derived from a CNN architecture:

- the encoder corresponds to the convolutional part of the CNN,
- the decoder is composed of the transposed version of the operations used in the encoder.

![Transfer learning from autoencoders to CNNs](../images/transfer_learning.png)

The list of the transposed version of modules can be found below:

- `Conv3d` → `ConvTranspose3d`
- `PadMaxPool3d` → `CropMaxUnpool3d` 
(specific module of `clinicadl` used to reconstruct the feature map produced by pooling layers with adaptive padding)
- `MaxPool3d` → `MaxUnpool3d`
- `Linear` → `Linear` with an inversion in `in_features` and `out_features`,
- `Flatten` → `Reshape`
- `LeakyReLU` → `LeakyReLU` with the inverse value of alpha,
- other → copy of itself

### Transfer learning

It is possible to transfer trainable parameters between models. In the following list the weights are transferred from `source task` to `target task`:

- `autoencoder` to `cnn`: the trainable parameters of the convolutional part of the `cnn` 
(convolutions and batch normalization layers) take the values of the trainable parameters of the encoder part of the source autoencoder,
- `cnn` to `cnn`: all the trainable parameters are transferred between the two models.
- `autoencoder` to `multicnn`: the convolutional part of each CNN of the `multicnn` run is initialized
 with the weights of the encoder of the source autoencoder.
- `cnn` to `multicnn`: each CNN of the `multicnn` run is initialized with the weights of the source CNN.
- `multicnn` to `multicnn`: each CNN is initialized with the weights of the corresponding one in the source experiment.

